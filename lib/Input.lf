/**
 * @file Input.lf
 * @author Vincenzo Barbuto
 * @author Edward A. Lee
 * @brief Interface library for input devices such as microphones, cameras, and other sensors.
 */
target Python

/**
 * @brief The `Microphone` reactor is responsible for capturing real-time audio data from a
 * microphone device and emitting it as an output.
 * 
 * It uses the `sounddevice` library to open an audio input stream, and provides a callback function that is 
 * called whenever new audio data is available. The recorded audio data is then scheduled to be emitted through 
 * the `audio_data` output.
 * 
 * Args:
 *  buffer_size (int): The size of the audio buffer in samples.
 *  sample_rate (int): The sample rate of the audio in Hz.
 *  channels (int): The number of audio channels.
 *  execution_mode (int): The execution mode of the reactor. 0 for realtime, 1 for recoding. Defaults to 0 (realtime).
 *  device (Optional[int]): The audio device to use for recording, or `None` to use the default device.
 *  dtype (Optional[str]): The data type of the audio data: 'float32', 'int32', 'int16', 'int8', 'uint8'. Defaults to `None`.
 * 
 * Reactions:
 *  startup: Starts the audio input stream and begins recording audio.
 *  realtime_mode: Starts the audio input stream in realtime mode; schedules audio data to be emitted through the `audio_data` output.
 *  recoding_mode: Starts the audio input stream in recoding mode; schedules audio data to be emitted through the `audio_data` output.
 *  send_audio_data: Emits the recorded audio data through the `audio_data` output.
 *  shutdown: Stops the audio input stream and shuts down the reactor.
*/
reactor Microphone(
    buffer_size=15600,
    sample_rate=16000,
    channels=1,
    execution_mode=0,
    device = {= None =},
    dtype = {= None =}) {
  logical action realtime_mode
  logical action recoding_mode
  physical action send_audio_data

  output audio_data

  state stream
  state q
  state stop_recording
  state audio_array

  preamble {=
    import sounddevice as sd
    import numpy as np
    import threading
    import queue
  =}

  reaction(startup) -> realtime_mode, recoding_mode {=
    if(self.execution_mode == 0):
      print("Starting Microphone in REALTIME mode")
      realtime_mode.schedule(0)
    elif(self.execution_mode == 1):
      print("Starting Microphone in RECORDING mode")
      print("Press Enter to start recording")
      input()
      recoding_mode.schedule(0)
  =}

  reaction(realtime_mode) -> send_audio_data {=
    def callback(indata, frames, time, status):
      if status:
        print(status)
      if(self.dtype is not None):
        indata = indata.astype(self.dtype)
      send_audio_data.schedule(0, indata)

    self.stream = self.sd.InputStream(
      channels=self.channels,
      samplerate=self.sample_rate,
      blocksize=self.buffer_size,
      callback=callback,
      dtype=self.dtype,
      device=self.device)
    self.stream.start()
    print("#" * 50)
    print("Recording started")
    print("#" * 50)
  =}

  reaction(recoding_mode) -> send_audio_data {=
    self.q = self.queue.Queue()
    self.stop_recording = self.threading.Event()
    self.audio_array = []

    def recording_callback(indata, frames, time, status):
      if status:
        print(status)
      self.q.put(indata.copy())

    def monitor_stop():
      input()
      self.stop_recording.set()

    with self.sd.InputStream(
      channels=self.channels,
      samplerate=self.sample_rate,
      dtype=self.dtype,
      device=self.device,
      callback=recording_callback):

      print('#' * 80)
      print("Recording... Press Enter to stop.")
      print('#' * 80)

      stop_thread = self.threading.Thread(target=monitor_stop)
      stop_thread.start()

      while not self.stop_recording.is_set():
        self.audio_array.append(self.q.get())

      stop_thread.join()

    print("Recording stopped")
    self.audio_array = self.np.concatenate(self.audio_array)
    send_audio_data.schedule(0, self.audio_array)
  =}

  reaction(send_audio_data) -> audio_data {=
    audio_data.set(send_audio_data.value)
  =}

  reaction(shutdown) {=
    if self.stream:
      self.stream.stop()
    print("Shutting down Microphone reactor")
  =}
}

/**
 * @brief The `Camera` reactor is responsible for capturing real-time video data from 
 * a camera device and emitting it as an output.
 *
 * Args: 
 *  camera_id (int): The ID of the camera to use for capturing video. 
 *  offset (float): The initial offset in seconds for the start timer. 
 *  fps (int): The desired frames per second for the video capture.
 *
 * Reactions: 
 *  start: Initializes the camera stream and captures the first frame. 
 *  trigger: Captures a new video frame and emits it through the `camera_frame` output. 
 *  shutdown: Releases the camera stream.
 *
 * Inputs: 
 *  trigger: Triggers the capture of a new video frame.
 *
 * Outputs: 
 *  camera_frame: The captured video frame.
 */
reactor Camera(camera_id=0, offset = 0 s, fps=30) {
  input trigger
  output camera_frame

  timer start(offset)
  state stream

  preamble {=
    import cv2
    import sys
  =}

  reaction(start) -> camera_frame {=
    self.stream = self.cv2.VideoCapture(self.camera_id, self.cv2.CAP_ANY)
    if (self.stream.isOpened() == False):
      self.sys.stderr.write("Error: Failed to open the camera.\n")
      exit(1)

    self.stream.set(self.cv2.CAP_PROP_FPS, self.fps)

    # Read the first frame. This is a blocking read.
    ret, frame = self.stream.read()
    if ret is True:
      camera_frame.set(frame)
    else:
      print("Warning, failed to get first frame.")
  =}

  reaction(trigger) -> camera_frame {=
    # Read a frame. This is a blocking read.
    ret, frame = self.stream.read()
    if ret is True:
      camera_frame.set(frame)
    else:
      print("Warning, failed to get first frame.")
  =}

  reaction(shutdown) {=
    self.stream.release()
  =}
}
