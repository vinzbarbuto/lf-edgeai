/**
 * File containing Library of Reactor Components for Audio tasks. This library provides a set of
 * reusable and optimized components for performing various audio tasks, such as audio
 * classification, with high performance and efficiency.
 *
 * @author Vincenzo Barbuto
 */

target Python

import MLReactor from "../lib/Abstract.lf"


/**
 *
 * Reactor that extends `Classifier` reactor performing audio classification using a TensorFlow Lite model.
 *
 * Args:
 *    model (str): Absolute path to the TensorFlow Lite model file.
 *    max_results (int): Maximum number of classification results to return.
 *    score_threshold (float): Minimum score threshold for classification results.
 *    num_threads (int): Number of CPU threads to use for inference.
 *    enable_edgetpu (bool): Whether to use the Edge TPU for inference.
 *
 * Inputs:
 *    input_data (numpy.ndarray): Audio data to be classified.
 *
 * Outputs:
 *    results (list[dict]): List of classification results, where each result is a dictionary with the following keys:
 *        - index (int): Index of the classification result.
 *        - label (str): Class label of the classification result.
 *        - score (float): Confidence score of the classification result.
 *        - head (str): Name of the classification head.
 *    inference_time (float): Time taken to perform the classification, in milliseconds.
 *
 *
*/

reactor AudioClassifier extends MLReactor {

  preamble {=
    
    from tflite_support.task import audio, core, processor

    def collect_results(self, classifications):
        results_list = []
        for classification in classifications:
            results_list.append({
                "index": classification.categories[0].index,
                "label": classification.categories[0].category_name,
                "score": classification.categories[0].score,
                "head": classification.head_name
            })
        return results_list;
  =}

  reaction(startup) {=
    if(self.model == ""):
        print("Error: Please provide a valid model path")
        request_stop()
    else:
        classification_options = self.processor.ClassificationOptions(
            max_results=self.max_results, score_threshold=self.score_threshold)
        options = self.audio.AudioClassifierOptions(
            base_options=self.base_options, classification_options=classification_options)
        self.classifier = self.audio.AudioClassifier.create_from_options(options)

        self.tensor_input = self.classifier.create_input_tensor_audio()
  =}

  reaction(input_data) -> results, inference_time {=
    if(input_data.is_present):
        # Run inference
        self.tensor_input.load_from_array(input_data.value)
        # Load the input audio and run classify.
        start = lf.time.physical()
        result = self.classifier.classify(self.tensor_input)
        end = (lf.time.physical() - start) / 1000000
        results.set(self.collect_results(result.classifications))
        inference_time.set(end)
    else:
        print("Error: Input data is not present")
        request_stop()
  =}

  reaction(shutdown) {=
    print("Shutting down AudioClassifier reactor")
  =}
}
