target Python

/*
Reactor that performs audio classification using a TensorFlow Lite model.

Args:
    model (str): Absolute path to the TensorFlow Lite model file.
    max_results (int): Maximum number of classification results to return.
    score_threshold (float): Minimum score threshold for classification results.
    num_threads (int): Number of CPU threads to use for inference.
    enable_edgetpu (bool): Whether to use the Edge TPU for inference.

Inputs:
    input_data (numpy.ndarray): Audio data to be classified.

Outputs:
    results (list[dict]): List of classification results, where each result is a dictionary with the following keys:
        - label (str): Class label of the classification result.
        - score (float): Confidence score of the classification result.
        - head (str): Name of the classification head.
    inference_time (float): Time taken to perform the classification, in milliseconds.

    @author Vincenzo Barbuto

*/
reactor AudioClassifier(model="", max_results=5, score_threshold=0.0, num_threads=4, enable_edgetpu=False) {
    state classifier;
    state tensor_audio;

    input input_data;
    
    output results;
    output inference_time;

    preamble {=
        from tflite_support.task import audio
        from tflite_support.task import core
        from tflite_support.task import processor
        
        import time

        def collect_results(self, classifications):
            results_list = []
            for classification in classifications:
                results_list.append({
                    "label": classification.categories[0].category_name,
                    "score": classification.categories[0].score,
                    "head": classification.head_name
                })
            return results_list;



    =}

    reaction(startup) {=
        if(self.model == ""):
            print("Error: Please provide a valid model path")
            request_stop()
        else:
            # Initialize the audio classification model.
            base_options = self.core.BaseOptions(
                file_name=self.model, use_coral=self.enable_edgetpu, num_threads=self.num_threads)
            classification_options = self.processor.ClassificationOptions(
                max_results=self.max_results, score_threshold=self.score_threshold)
            options = self.audio.AudioClassifierOptions(
                base_options=base_options, classification_options=classification_options)
            self.classifier = self.audio.AudioClassifier.create_from_options(options)

            self.tensor_audio = self.classifier.create_input_tensor_audio()
    =}

    reaction(input_data) -> results, inference_time {=
        # Run inference
        self.tensor_audio.load_from_array(input_data.value)
        # Load the input audio and run classify.
        start = lf.time.physical()
        result = self.classifier.classify(self.tensor_audio)
        end = (lf.time.physical() - start) / 1000000
        results.set(self.collect_results(result.classifications))
        inference_time.set(end)
    =}

    reaction(shutdown) {=
        print("Shutting down AudioClassifier reactor")
    =}

}