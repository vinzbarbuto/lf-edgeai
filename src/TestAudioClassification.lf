/**
 * @file
 * @author Vincenzo Barbuto
 * @brief Examples of how to use the Audio Classification reactor.
 */

target Python

import Microphone from "../lib/Input.lf"
import AudioClassifier from "../lib/Audio.lf"

/**
 * @brief This reactor tests the audio classification functionality by connecting a Microphone, an AudioClassifier, 
 * and an ActuatorTest reactor.
 * 
 * The `ActuatorTest` reactor receives the classification results and inference time from the `AudioClassifier` 
 * and prints them to the console.
 * 
 * The `main` reactor creates instances of the `Microphone`, `AudioClassifier`, and `ActuatorTest` reactors, 
 * and connects them together to form the test pipeline.
 *
 * @note Remember to set the `model` parameter to the absolute path of the audio classification model you want to use.
*/

reactor ActuatorTest {
    input input1
    input input2

    reaction(input1, input2) {=
        results = input1.value
        print("-"*70)
        for i, result in enumerate(results):
            print(f"{i}) Head: {result['head']}, Index: {result['index']}, Label: {result['label']}, Confidence: {result['score']*100:.2f}%")
        print(f"Time per inference: {input2.value} ms")
    =}
}


main reactor {
    mic = new Microphone();
    cls = new AudioClassifier(model="/path/to/model.tflite");
    actuator = new ActuatorTest();
    mic.audio_data -> cls.input_data;
    cls.results, cls.inference_time -> actuator.input1, actuator.input2;
}